{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0 10\n",
      "1 10\n",
      "2 10\n",
      "3 10\n",
      "4 10\n",
      "5 10\n",
      "6 10\n",
      "7 10\n",
      "8 10\n",
      "9 10\nдоискались что сгоряча послали команду \n всем откудова-то было достоверно известно с шатовым хотя по-видимому и пари держу — говорил\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from string import punctuation\n",
    "\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "start = '<start>'\n",
    "end = '<end>'\n",
    "\n",
    "\n",
    "def normalize(text):\n",
    "    normalized_text = [word.strip(punctuation) for word in text.lower().split()]\n",
    "    normalized_text = [word for word in normalized_text if word]\n",
    "    return normalized_text\n",
    "\n",
    "\n",
    "def ngrammer(tokens, n=3):\n",
    "    ngrams = []\n",
    "    for i in range(0, len(tokens) - n + 1):\n",
    "        ngrams.append(' '.join(tokens[i:i + n]))\n",
    "    return ngrams\n",
    "\n",
    "\n",
    "def generate(matrix, id2word, word2id, n=10, st=start):\n",
    "    text = []\n",
    "    first_idx = word2id[st]\n",
    "\n",
    "    for i in range(n):\n",
    "        idx = 0\n",
    "        temp_list = []\n",
    "        for _ in matrix[first_idx]:\n",
    "            temp_list.append(max(matrix[first_idx][idx]))\n",
    "            idx += 1\n",
    "        sum = np.array(temp_list).sum()\n",
    "        if sum > 0:\n",
    "            props = [i / sum for i in temp_list]\n",
    "            chosen_second = np.random.choice(np.arange(len(temp_list)), p=props)\n",
    "        else:\n",
    "            chosen_second = word2id[end]\n",
    "        text.append(id2word[chosen_second])\n",
    "        if id2word[chosen_second] == end:\n",
    "            chosen_second = word2id[start]\n",
    "\n",
    "        temp_list = matrix[first_idx][chosen_second]\n",
    "        sum = np.array(temp_list).sum()\n",
    "\n",
    "        if sum > 0:\n",
    "            props = [i / sum for i in temp_list]\n",
    "            chosen_third = np.random.choice(np.arange(len(temp_list)), p=props)\n",
    "        else:\n",
    "            chosen_third = word2id[end]\n",
    "        text.append(id2word[chosen_third])\n",
    "        if id2word[chosen_third] == end:\n",
    "            chosen_third = word2id[start]\n",
    "        first_idx = chosen_third\n",
    "        print(i, n)\n",
    "\n",
    "    return ' '.join(text)\n",
    "\n",
    "\n",
    "# ----------\n",
    "\n",
    "dostoevsky = open('besy_dostoevsky.txt', encoding='cp1251').read()\n",
    "tolstoy = open('anna_karenina.txt').read()\n",
    "\n",
    "norm_dostoevsky = normalize(dostoevsky)\n",
    "norm_tolstoy = normalize(tolstoy)\n",
    "unique_norm_dostoevsky = set(norm_dostoevsky)\n",
    "unique_norm_tolstoy = set(norm_tolstoy)\n",
    "\n",
    "sentences_dostoevsky = [[start] + normalize(text) + [end] for text in sent_tokenize(dostoevsky)][:1000]\n",
    "sentences_tolstoy = [[start] + normalize(text) + [end] for text in sent_tokenize(tolstoy)][:1000]\n",
    "# ----------\n",
    "unigrams_dostoevsky = Counter()\n",
    "threegrams_dostoevsky = Counter()\n",
    "\n",
    "for sentence in sentences_dostoevsky:\n",
    "    unigrams_dostoevsky.update(sentence)\n",
    "    threegrams_dostoevsky.update(ngrammer(sentence))\n",
    "\n",
    "unigrams_tolstoy = Counter()\n",
    "threegrams_tolstoy = Counter()\n",
    "\n",
    "for sentence in sentences_tolstoy:\n",
    "    unigrams_tolstoy.update(sentence)\n",
    "    threegrams_tolstoy.update(ngrammer(sentence))\n",
    "\n",
    "# ----------\n",
    "len_unigrams_dostoevsky = len(unigrams_dostoevsky)\n",
    "matrix_dostoevsky = np.zeros((\n",
    "    len_unigrams_dostoevsky,\n",
    "    len_unigrams_dostoevsky,\n",
    "    len_unigrams_dostoevsky\n",
    "))\n",
    "id2word_dostoevsky = list(unigrams_dostoevsky)\n",
    "word2id_dostoevsky = {word: i for i, word in enumerate(id2word_dostoevsky)}\n",
    "\n",
    "for ngram in threegrams_dostoevsky:\n",
    "    word1, word2, word3 = ngram.split()\n",
    "    matrix_dostoevsky[word2id_dostoevsky[word1]][word2id_dostoevsky[word2]][word2id_dostoevsky[word3]] \\\n",
    "        = (threegrams_dostoevsky[ngram] / unigrams_dostoevsky[word1])\n",
    "\n",
    "len_unigrams_tolstoy = len(unigrams_tolstoy)\n",
    "matrix_tolstoy = np.zeros((\n",
    "    len_unigrams_tolstoy,\n",
    "    len_unigrams_tolstoy,\n",
    "    len_unigrams_tolstoy\n",
    "))\n",
    "id2word_tolstoy = list(unigrams_tolstoy)\n",
    "word2id_tolstoy = {word: i for i, word in enumerate(id2word_tolstoy)}\n",
    "\n",
    "for ngram in threegrams_tolstoy:\n",
    "    word1, word2, word3 = ngram.split()\n",
    "    matrix_tolstoy[word2id_tolstoy[word1]][word2id_tolstoy[word2]][word2id_tolstoy[word3]] \\\n",
    "        = (threegrams_tolstoy[ngram] / unigrams_tolstoy[word1])\n",
    "\n",
    "# ----------\n",
    "\n",
    "print(generate(matrix_dostoevsky, id2word_dostoevsky, word2id_dostoevsky).replace(end, '\\n'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}